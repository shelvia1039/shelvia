---
layout: post
title: Welcoming 2020
image: /assets/blogs/2020.jpg
description: >
  Starting the new year right.
---


It's a new year and a new decade. In this post, I would like to list out some of the things that I have planned out for this year. After reflecting on the previous year 2019, I realized that there are so many things that I still want to achieve. I know I have to start now because my second year of PhD life just kicks off. These small but impactful targets are important ingredients to master the recipe of becoming a deep learning scientist (I don't know if such position exists, but I would love to be called that in the future). I also came to a realization that the Doctoral degree that will be conferred to me in 3 years time (or so I hope) comes with huge responsibilities such as conveying the right knowledge and message to the ones that I will work with in the future or when I am being asked a question or a piece of advice. In other words, really I have to be the expert in the field (part of the 1% of the population perhaps) so that I could give worthy advice to those who lack the judgement and intuition.


**Contents**:
* 
{:toc}

## More directed research
As my PhD Qualifying Exam (PQE) is drawing near, I need to consolidate my research results. In my first year, I have been exploring different topics including information bottleneck, lottery ticket hypothesis, randomly wired neural network, deep image reconstruction as well as roles of intermediate layers. Although I believe that they are critical to understanding deep learning better, I have chosen to focus on the stability analysis of neural network as my research for this year.

Since my plan after graduation is to work in industry, I try to structure my PhD thesis such that it is one big project consisting of several small but related projects (ideally three of them). Nevertheless, I would have to go deep enough for each of the project such that it is worthy enough of a paper. My plan is to understand deep learning from three different perspectives: physics, information theory and neuroscience. For 2020, I would focus my research on understanding deep learning from physics point of view. Hopefully, I would be able to publish a paper on that and go for a conference this year.

## #100daysofML Challenge
To be honest, I have only started gaining an understanding of Machine Learning (ML) in my first year of PhD. As I have been learning from different sources, I am not yet confident about the fundamentals. Hence, I would like to create the #100daysofML challenge to motivate myself to brush up my basics as well as practise the exploratory data analysis part. I will also take this chance to track what I learn and record all the relevant resources that I use in case I would need to refer to them again in the future.

Sources I will use:
- books and courses (for fundamentals)
- projects from Kaggle (for practice)

Rules:
- Dedicate one hour to machine learning everyday.
- Make a public log of my work and update it daily (most probably on Github).
- Research or course work will not be counted towards the hours.
- I am allowed to skip only a day in a week for "free". If I skip n days in a week, I would need to dedicate n additional hour(s) on the weekend.

## #100daysofCode Challenge
Similarly, I started coding not too long ago as my undergraduate work is mainly theoretical. Therefore, I would need to improve my coding skill. Since I will be doing the #100daysofML challenge concurrently, I would like this #100daysofCode challenge to be more relaxed and more focused on getting familiar with the language itself. I think sharpening my logic is important and therefore this will be the objective of this challenge.

Language I will be coding in: Python

Sources I will use:
- books and courses (for fundamentals)
- puzzle solving websites such as CodinGame and codewars (for practice)
- mobile apps such as sololearn (for busy period)

Rules:
- Dedicate half an hour to coding in the language everyday.
- Coding for research purposes or other challenges will not counted.
- I am allowed to skip only a day in a week for "free". If I skip n days in a week, I would need to dedicate n/2 additional hour(s) on the weekend.

## #1PaperAday Challenge
As deep learning field is advancing rapidly, there are lots of papers being published every single day. In order to keep up with what's going on in the field, I have set up the last challenge: #1PaperAday. The goal is not only to be aware of the latest research but also to have the knowledge of great research ideas from the past decade. This will definitely benefit my research in the future.

Sources I will use:
- Arxiv Sanity Preserver (for latest research)
- Conference papers (for present and past research)
- Medium articles (for sourcing good research ideas)

Rules:
- Dedicate half an hour to read a paper or article everyday and another half an hour to summarize the main ideas (on Medium).
- I am allowed to skip only a day in a week for "free". If I skip n days in a week, I would need to dedicate n additional hour(s) on the weekend.

## Areas to explore
Aside from machine learning, there are several other areas that I would like to explore this year:
- database
- big data analytics
- linux systems